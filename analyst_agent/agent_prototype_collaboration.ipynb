{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26e1ce4-5beb-43d4-ae2a-76a5aec960a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "with open('/Users/marie/Documents/github/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "    for key in config:\n",
    "        os.environ[key] = config[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08087821-6921-4b5c-bb80-dcea68933805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51cacb3-cddc-428c-8e1c-aad986f33a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8f6a84-b616-413d-becd-4503e0851f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282ecf9c-079d-4dea-b699-f9e857955e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23689fd4-3b41-42df-97a2-bb3a692d0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ab39d-b619-4271-b3aa-3b799ede0b8c",
   "metadata": {},
   "source": [
    "### OpenAI tools vs OpenAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c81e7d-2544-4ac8-b7d5-7c88d582600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''\n",
    "You are working as a product analyst for the e-commerce company. \n",
    "Your work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \n",
    "If you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\n",
    "You are very helpful and try your best to answer the questions.\n",
    "\n",
    "If you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \n",
    "You don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \n",
    "Always use tool if you have follow-up questions to the request.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5d56394e-7513-4830-b9eb-9b3aa3c586c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from langchain.agents import tool\n",
    "\n",
    "class Filters(BaseModel):\n",
    "    month: str = Field(description=\"Month of customer's activity in the format %Y-%m-%d\")\n",
    "    city: Optional[str] = Field(description=\"City of residence for customers (by default no filter)\", \n",
    "                    enum = [\"London\", \"Berlin\", \"Amsterdam\", \"Paris\"])\n",
    "\n",
    "@tool(args_schema=Filters)\n",
    "def get_monthly_active_users(month: str, city: str = None) -> int:\n",
    "    \"\"\"Returns number of active customers for the specified month. Pass month in format %Y-%m-01.\n",
    "    \"\"\"\n",
    "    coefs = {\n",
    "        'London': 2,\n",
    "        'Berlin': 1,\n",
    "        'Amsterdam': 0.5,\n",
    "        'Paris': 0.25\n",
    "    }\n",
    "    dt = datetime.datetime.strptime(month, '%Y-%m-%d')\n",
    "    total = dt.year + 10*dt.month\n",
    "    if city is None:\n",
    "        return total\n",
    "    else:\n",
    "        return int(round(coefs[city]*total))\n",
    "        \n",
    "        \n",
    "class Metrics(BaseModel):\n",
    "    metric1: float = Field(description=\"Base metric value to calculate the difference\")\n",
    "    metric2: float = Field(description=\"New metric value that we compare with the baseline\")\n",
    "\n",
    "@tool(args_schema=Metrics)\n",
    "def percentage_difference(metric1: float, metric2: float) -> float:\n",
    "    \"\"\"Calculates the percentage difference between metrics\"\"\"\n",
    "    return (metric2 - metric1)/metric1*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1473ff20-786e-4eab-9620-d0c32af47f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:tool:get_monthly_active_users] Entering Tool run with input:\n",
      "\u001b[0m\"{'month': '2023-12-01', 'city': 'London'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:tool:get_monthly_active_users] [1ms] Exiting Tool run with output:\n",
      "\u001b[0m\"4286\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4286"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_monthly_active_users.run({\"month\": \"2023-12-01\", \"city\": \"London\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5dfb96-7bfc-445e-9c8e-68dae8055c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:tool:get_monthly_active_users] Entering Tool run with input:\n",
      "\u001b[0m\"{'month': '2023-12-01', 'city': 'Berlin'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:tool:get_monthly_active_users] [1ms] Exiting Tool run with output:\n",
      "\u001b[0m\"2143\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2143"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_monthly_active_users.run({\"month\": \"2023-12-01\", \"city\": \"Berlin\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7730cef8-1e15-427a-9f9a-90afaa42a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc17bcb-f1fb-4363-a2c6-52658af503aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n",
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType, Tool, initialize_agent, create_openai_tools_agent, create_openai_functions_agent, AgentExecutor\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "tools = [get_monthly_active_users, percentage_difference]\n",
    "\n",
    "human_input_agent_tools = create_openai_tools_agent(\n",
    "    llm = ChatOpenAI(temperature=0.1, model = 'gpt-4-1106-preview'),\n",
    "    tools = tools, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "human_input_agent_tools_executor = AgentExecutor(\n",
    "    agent=human_input_agent_tools, tools=tools, \n",
    "    verbose=True, max_iterations=10, # early stopping criteria\n",
    "    early_stopping_method='generate')\n",
    "\n",
    "human_input_agent_funcs = create_openai_functions_agent(\n",
    "    llm = ChatOpenAI(temperature=0.1, model = 'gpt-4-1106-preview'),\n",
    "    tools = tools, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "human_input_agent_funcs_executor = AgentExecutor(\n",
    "    agent=human_input_agent_funcs, tools=tools, \n",
    "    verbose=True, max_iterations=10, # early stopping criteria\n",
    "    early_stopping_method='generate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6158ef2e-386e-4a3e-b575-ba9047c9eefa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:<lambda>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] [1.80s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 26,\n",
      "      \"prompt_tokens\": 381,\n",
      "      \"total_tokens\": 407\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"schema\",\n",
      "    \"agent\",\n",
      "    \"AgentActionMessageLog\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"tool\": \"get_monthly_active_users\",\n",
      "    \"tool_input\": {\n",
      "      \"month\": \"2023-12-01\",\n",
      "      \"city\": \"London\"\n",
      "    },\n",
      "    \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "    \"message_log\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "              \"name\": \"get_monthly_active_users\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [1.81s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_monthly_active_users] Entering Tool run with input:\n",
      "\u001b[0m\"{'month': '2023-12-01', 'city': 'London'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_monthly_active_users] [1ms] Exiting Tool run with output:\n",
      "\u001b[0m\"4286\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad> > 13:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad> > 13:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"4286\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"4286\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"AgentActionMessageLog\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"London\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      4286\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 14:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 14:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "              \"name\": \"get_monthly_active_users\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"FunctionMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\",\n",
      "          \"content\": \"4286\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 15:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\nAI: {'arguments': '{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}', 'name': 'get_monthly_active_users'}\\nFunction: 4286\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 15:llm:ChatOpenAI] [1.69s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 26,\n",
      "      \"prompt_tokens\": 420,\n",
      "      \"total_tokens\": 446\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 16:parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 16:parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"schema\",\n",
      "    \"agent\",\n",
      "    \"AgentActionMessageLog\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"tool\": \"get_monthly_active_users\",\n",
      "    \"tool_input\": {\n",
      "      \"month\": \"2023-12-01\",\n",
      "      \"city\": \"Berlin\"\n",
      "    },\n",
      "    \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\\n\\n\\n\",\n",
      "    \"message_log\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "              \"name\": \"get_monthly_active_users\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence] [1.70s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 17:tool:get_monthly_active_users] Entering Tool run with input:\n",
      "\u001b[0m\"{'month': '2023-12-01', 'city': 'Berlin'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 17:tool:get_monthly_active_users] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"2143\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad> > 20:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad> > 20:chain:RunnableParallel<agent_scratchpad> > 21:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad> > 20:chain:RunnableParallel<agent_scratchpad> > 21:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"4286\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"2143\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad> > 20:chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"4286\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"2143\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"AgentActionMessageLog\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"London\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      4286\n",
      "    ],\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"AgentActionMessageLog\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"Berlin\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      2143\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 22:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 22:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "              \"name\": \"get_monthly_active_users\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"FunctionMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\",\n",
      "          \"content\": \"4286\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "              \"name\": \"get_monthly_active_users\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"FunctionMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\",\n",
      "          \"content\": \"2143\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 23:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\nAI: {'arguments': '{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}', 'name': 'get_monthly_active_users'}\\nFunction: 4286\\nAI: {'arguments': '{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}', 'name': 'get_monthly_active_users'}\\nFunction: 2143\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 23:llm:ChatOpenAI] [1.10s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "                \"name\": \"percentage_difference\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 23,\n",
      "      \"prompt_tokens\": 459,\n",
      "      \"total_tokens\": 482\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_3905aa4f79\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 24:parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 24:parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"schema\",\n",
      "    \"agent\",\n",
      "    \"AgentActionMessageLog\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"tool\": \"percentage_difference\",\n",
      "    \"tool_input\": {\n",
      "      \"metric1\": 4286,\n",
      "      \"metric2\": 2143\n",
      "    },\n",
      "    \"log\": \"\\nInvoking: `percentage_difference` with `{'metric1': 4286, 'metric2': 2143}`\\n\\n\\n\",\n",
      "    \"message_log\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "              \"name\": \"percentage_difference\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence] [1.11s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 25:tool:percentage_difference] Entering Tool run with input:\n",
      "\u001b[0m\"{'metric1': 4286, 'metric2': 2143}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 25:tool:percentage_difference] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"-50.0\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 27:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 27:chain:RunnableAssign<agent_scratchpad> > 28:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 27:chain:RunnableAssign<agent_scratchpad> > 28:chain:RunnableParallel<agent_scratchpad> > 29:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 27:chain:RunnableAssign<agent_scratchpad> > 28:chain:RunnableParallel<agent_scratchpad> > 29:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"4286\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"2143\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "            \"name\": \"percentage_difference\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"percentage_difference\",\n",
      "        \"content\": \"-50.0\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 27:chain:RunnableAssign<agent_scratchpad> > 28:chain:RunnableParallel<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 27:chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"4286\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"get_monthly_active_users\",\n",
      "        \"content\": \"2143\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"function_call\": {\n",
      "            \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "            \"name\": \"percentage_difference\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"FunctionMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"percentage_difference\",\n",
      "        \"content\": \"-50.0\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"AgentActionMessageLog\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"London\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      4286\n",
      "    ],\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"AgentActionMessageLog\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"Berlin\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      2143\n",
      "    ],\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"AgentActionMessageLog\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"percentage_difference\",\n",
      "          \"tool_input\": {\n",
      "            \"metric1\": 4286,\n",
      "            \"metric2\": 2143\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `percentage_difference` with `{'metric1': 4286, 'metric2': 2143}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"function_call\": {\n",
      "                    \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "                    \"name\": \"percentage_difference\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      -50.0\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 30:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 30:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "              \"name\": \"get_monthly_active_users\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"FunctionMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\",\n",
      "          \"content\": \"4286\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "              \"name\": \"get_monthly_active_users\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"FunctionMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\",\n",
      "          \"content\": \"2143\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "              \"name\": \"percentage_difference\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"FunctionMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"name\": \"percentage_difference\",\n",
      "          \"content\": \"-50.0\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 31:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\nAI: {'arguments': '{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}', 'name': 'get_monthly_active_users'}\\nFunction: 4286\\nAI: {'arguments': '{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}', 'name': 'get_monthly_active_users'}\\nFunction: 2143\\nAI: {'arguments': '{\\\"metric1\\\":4286,\\\"metric2\\\":2143}', 'name': 'percentage_difference'}\\nFunction: -50.0\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 31:llm:ChatOpenAI] [1.98s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"In December 2023, the number of customers in London was 4,286, while in Berlin it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin in that month.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"In December 2023, the number of customers in London was 4,286, while in Berlin it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin in that month.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 61,\n",
      "      \"prompt_tokens\": 494,\n",
      "      \"total_tokens\": 555\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 32:parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence > 32:parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"schema\",\n",
      "    \"agent\",\n",
      "    \"AgentFinish\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"return_values\": {\n",
      "      \"output\": \"In December 2023, the number of customers in London was 4,286, while in Berlin it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin in that month.\"\n",
      "    },\n",
      "    \"log\": \"In December 2023, the number of customers in London was 4,286, while in Berlin it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin in that month.\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:RunnableSequence] [1.99s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [6.62s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"In December 2023, the number of customers in London was 4,286, while in Berlin it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin in that month.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'In December 2023, the number of customers in London was 4,286, while in Berlin it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin in that month.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input_agent_funcs_executor.invoke(\n",
    "    {'input': 'What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?', \n",
    "     'agent_scratchpad': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d1eba60-b521-433a-8927-5ce17b9ea646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:<lambda>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [],\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] [4.00s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                },\n",
      "                {\n",
      "                  \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 107,\n",
      "      \"prompt_tokens\": 381,\n",
      "      \"total_tokens\": 488\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"OpenAIToolAgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"get_monthly_active_users\",\n",
      "        \"tool_input\": {\n",
      "          \"month\": \"2023-12-01\",\n",
      "          \"city\": \"London\"\n",
      "        },\n",
      "        \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "        \"message_log\": [\n",
      "          {\n",
      "            \"lc\": 1,\n",
      "            \"type\": \"constructor\",\n",
      "            \"id\": [\n",
      "              \"langchain\",\n",
      "              \"schema\",\n",
      "              \"messages\",\n",
      "              \"AIMessage\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"content\": \"\",\n",
      "              \"additional_kwargs\": {\n",
      "                \"tool_calls\": [\n",
      "                  {\n",
      "                    \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                    \"function\": {\n",
      "                      \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                      \"name\": \"get_monthly_active_users\"\n",
      "                    },\n",
      "                    \"type\": \"function\"\n",
      "                  },\n",
      "                  {\n",
      "                    \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                    \"function\": {\n",
      "                      \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                      \"name\": \"get_monthly_active_users\"\n",
      "                    },\n",
      "                    \"type\": \"function\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"OpenAIToolAgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"get_monthly_active_users\",\n",
      "        \"tool_input\": {\n",
      "          \"month\": \"2023-12-01\",\n",
      "          \"city\": \"Berlin\"\n",
      "        },\n",
      "        \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\\n\\n\\n\",\n",
      "        \"message_log\": [\n",
      "          {\n",
      "            \"lc\": 1,\n",
      "            \"type\": \"constructor\",\n",
      "            \"id\": [\n",
      "              \"langchain\",\n",
      "              \"schema\",\n",
      "              \"messages\",\n",
      "              \"AIMessage\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"content\": \"\",\n",
      "              \"additional_kwargs\": {\n",
      "                \"tool_calls\": [\n",
      "                  {\n",
      "                    \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                    \"function\": {\n",
      "                      \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                      \"name\": \"get_monthly_active_users\"\n",
      "                    },\n",
      "                    \"type\": \"function\"\n",
      "                  },\n",
      "                  {\n",
      "                    \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                    \"function\": {\n",
      "                      \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                      \"name\": \"get_monthly_active_users\"\n",
      "                    },\n",
      "                    \"type\": \"function\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [4.01s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_monthly_active_users] Entering Tool run with input:\n",
      "\u001b[0m\"{'month': '2023-12-01', 'city': 'London'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_monthly_active_users] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"4286\"\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:get_monthly_active_users] Entering Tool run with input:\n",
      "\u001b[0m\"{'month': '2023-12-01', 'city': 'Berlin'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:tool:get_monthly_active_users] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"2143\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableAssign<agent_scratchpad> > 13:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableAssign<agent_scratchpad> > 13:chain:RunnableParallel<agent_scratchpad> > 14:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableAssign<agent_scratchpad> > 13:chain:RunnableParallel<agent_scratchpad> > 14:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            },\n",
      "            {\n",
      "              \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "        \"content\": \"4286\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "        \"content\": \"2143\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableAssign<agent_scratchpad> > 13:chain:RunnableParallel<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 12:chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            },\n",
      "            {\n",
      "              \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "        \"content\": \"4286\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "        \"content\": \"2143\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"London\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\"\n",
      "        }\n",
      "      },\n",
      "      4286\n",
      "    ],\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"Berlin\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\"\n",
      "        }\n",
      "      },\n",
      "      2143\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 15:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 15:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                  \"name\": \"get_monthly_active_users\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                  \"name\": \"get_monthly_active_users\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "          \"content\": \"4286\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "          \"content\": \"2143\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 16:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\nAI: \\nTool: 4286\\nTool: 2143\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 16:llm:ChatOpenAI] [1.80s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "                    \"name\": \"percentage_difference\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 23,\n",
      "      \"prompt_tokens\": 466,\n",
      "      \"total_tokens\": 489\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 17:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence > 17:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"OpenAIToolAgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"percentage_difference\",\n",
      "        \"tool_input\": {\n",
      "          \"metric1\": 4286,\n",
      "          \"metric2\": 2143\n",
      "        },\n",
      "        \"log\": \"\\nInvoking: `percentage_difference` with `{'metric1': 4286, 'metric2': 2143}`\\n\\n\\n\",\n",
      "        \"message_log\": [\n",
      "          {\n",
      "            \"lc\": 1,\n",
      "            \"type\": \"constructor\",\n",
      "            \"id\": [\n",
      "              \"langchain\",\n",
      "              \"schema\",\n",
      "              \"messages\",\n",
      "              \"AIMessage\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"content\": \"\",\n",
      "              \"additional_kwargs\": {\n",
      "                \"tool_calls\": [\n",
      "                  {\n",
      "                    \"id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "                    \"function\": {\n",
      "                      \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "                      \"name\": \"percentage_difference\"\n",
      "                    },\n",
      "                    \"type\": \"function\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"tool_call_id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 11:chain:RunnableSequence] [1.81s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:tool:percentage_difference] Entering Tool run with input:\n",
      "\u001b[0m\"{'metric1': 4286, 'metric2': 2143}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:tool:percentage_difference] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"-50.0\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 20:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 20:chain:RunnableAssign<agent_scratchpad> > 21:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 20:chain:RunnableAssign<agent_scratchpad> > 21:chain:RunnableParallel<agent_scratchpad> > 22:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 20:chain:RunnableAssign<agent_scratchpad> > 21:chain:RunnableParallel<agent_scratchpad> > 22:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            },\n",
      "            {\n",
      "              \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "        \"content\": \"4286\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "        \"content\": \"2143\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "                \"name\": \"percentage_difference\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "        \"content\": \"-50.0\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"percentage_difference\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 20:chain:RunnableAssign<agent_scratchpad> > 21:chain:RunnableParallel<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 20:chain:RunnableAssign<agent_scratchpad>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "  \"agent_scratchpad\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            },\n",
      "            {\n",
      "              \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "        \"content\": \"4286\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "        \"content\": \"2143\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "                \"name\": \"percentage_difference\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "        \"content\": \"-50.0\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"percentage_difference\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"London\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\"\n",
      "        }\n",
      "      },\n",
      "      4286\n",
      "    ],\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"Berlin\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\"\n",
      "        }\n",
      "      },\n",
      "      2143\n",
      "    ],\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"percentage_difference\",\n",
      "          \"tool_input\": {\n",
      "            \"metric1\": 4286,\n",
      "            \"metric2\": 2143\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `percentage_difference` with `{'metric1': 4286, 'metric2': 2143}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "                        \"name\": \"percentage_difference\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\"\n",
      "        }\n",
      "      },\n",
      "      -50.0\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 23:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 23:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"London\\\"}\",\n",
      "                  \"name\": \"get_monthly_active_users\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"month\\\": \\\"2023-12-01\\\", \\\"city\\\": \\\"Berlin\\\"}\",\n",
      "                  \"name\": \"get_monthly_active_users\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_H6ABDLEAi6th8yBfYFacwFPz\",\n",
      "          \"content\": \"4286\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_GzXyOl2FFNUwbnQ6DPZmXJmG\",\n",
      "          \"content\": \"2143\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"metric1\\\":4286,\\\"metric2\\\":2143}\",\n",
      "                  \"name\": \"percentage_difference\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_SfGg8kssDPwAqJnRO88ZtHdX\",\n",
      "          \"content\": \"-50.0\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"percentage_difference\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 24:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\nAI: \\nTool: 4286\\nTool: 2143\\nAI: \\nTool: -50.0\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 24:llm:ChatOpenAI] [2.91s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 59,\n",
      "      \"prompt_tokens\": 501,\n",
      "      \"total_tokens\": 560\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 25:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence > 25:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"schema\",\n",
      "    \"agent\",\n",
      "    \"AgentFinish\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"return_values\": {\n",
      "      \"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"\n",
      "    },\n",
      "    \"log\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 19:chain:RunnableSequence] [2.92s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [8.75s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input_agent_tools_executor.invoke(\n",
    "    {'input': 'What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?', \n",
    "     'agent_scratchpad': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "509b4bdf-a5c8-418d-a69c-721b14f971b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "407 + 446 + 482 + 539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37708837-4a19-401c-aa81-86a340d27f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1537"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "488 + 489 + 560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbcc85bb-799c-49cb-a2b7-47657a376ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121.92582953806115"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1874/1537*100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e106bf9-5108-4b0c-a5bf-e1daecd7ae3f",
   "metadata": {},
   "source": [
    "### Human tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5df86916-49b2-44f6-bcea-9aa41ab1b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import HumanInputRun\n",
    "human_tool = HumanInputRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03ffc822-90ca-4f0e-857f-992a813d7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''\n",
    "You are working as a product analyst for the e-commerce company. \n",
    "Your work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \n",
    "If you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\n",
    "You are very helpful and try your best to answer the questions.\n",
    "\n",
    "If you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \n",
    "You don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \n",
    "Always use tool if you have follow-up questions to the request.\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5bf020a-ba4c-4b46-829f-a073f9abcbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:tool:human] Entering Tool run with input:\n",
      "\u001b[0m\"{'query': \"What's your name?\"}\"\n",
      "\n",
      "\n",
      "What's your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Maria\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:tool:human] [8.19s] Exiting Tool run with output:\n",
      "\u001b[0m\"Maria\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Maria'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_tool.run({'query': \"What's your name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82464e27-a817-4ac7-8237-037853ee9dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can ask a human for guidance when you think you got stuck or you are not sure what to do next. The input should be a question for the human.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21144d81-3b97-4312-9de7-eef3c6694504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6265070a-e11a-4f77-91fb-d893bf24861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_tool.args_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c75be574-25b0-48e3-9ff2-dd4c61bf3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "tools = [get_monthly_active_users, percentage_difference, human_tool]\n",
    "\n",
    "human_input_agent = create_openai_tools_agent(\n",
    "    llm = ChatOpenAI(temperature=0.2, model = 'gpt-4-1106-preview'),\n",
    "    tools = tools, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "human_input_agent_executor = AgentExecutor(\n",
    "    agent=human_input_agent, tools=tools, \n",
    "    verbose=True, max_iterations=10, # early stopping criteria\n",
    "    early_stopping_method='generate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f18c120f-fe5a-42a1-b13f-4b70eb80adb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo provide you with the number of customers in London, I need to know the specific time period you are interested in. Are you looking for the number of monthly active users in London for a particular month, or do you need a different metric? Please provide the time frame or specify the metric you need.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the number of customers in London?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'To provide you with the number of customers in London, I need to know the specific time period you are interested in. Are you looking for the number of monthly active users in London for a particular month, or do you need a different metric? Please provide the time frame or specify the metric you need.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input_agent_executor.invoke(\n",
    "    {'input': 'What are the number of customers in London?', \n",
    "     'agent_scratchpad': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db3a3b3f-8d2c-4170-aa68-45e5bb42332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_tool = HumanInputRun(\n",
    "    description = 'You can use this tool to ask the user for the details related to the request. Always use this tool if you have follow-up questions. The input should be a question for the user. Be concise, polite and professional when asking the questions.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8568572-8b06-49c4-b40f-4553289c2326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can use this tool to ask the user for the details related to the request. Always use this tool if you have follow-up questions. The input should be a question for the user. Be concise, polite and professional when asking the questions.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdea05a8-c30a-4eb5-b9fe-b5d6e679c025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "tools = [get_monthly_active_users, percentage_difference, human_tool]\n",
    "\n",
    "human_input_agent = create_openai_tools_agent(\n",
    "    llm = ChatOpenAI(temperature=0.1, model = 'gpt-4-1106-preview'),\n",
    "    tools = tools, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "human_input_agent_executor = AgentExecutor(\n",
    "    agent=human_input_agent, tools=tools, \n",
    "    verbose=True, max_iterations=10, # early stopping criteria\n",
    "    early_stopping_method='generate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0ae319c-8017-4daa-8e17-0389e5586e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `human` with `Could you please specify the time period for which you would like to know the number of customers in London?`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "Could you please specify the time period for which you would like to know the number of customers in London?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " December 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mDecember 2023\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m4286\u001b[0m\u001b[32;1m\u001b[1;3mThe number of active customers in London for December 2023 is 4,286.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the number of customers in London?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'The number of active customers in London for December 2023 is 4,286.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input_agent_executor.invoke(\n",
    "    {'input': 'What are the number of customers in London?', \n",
    "     'agent_scratchpad': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c91a6-2843-4e0b-8a23-69f87d0c7a1a",
   "metadata": {},
   "source": [
    "###Memory basics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8cd0645d-a9ba-47ac-a4dd-26cdd0a8fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationTokenBufferMemory, ConversationSummaryBufferMemory\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c40f4fa4-9433-4165-bd82-e6c6315515cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hey, how are you? How was your weekend?\n",
      "AI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hey, how are you? How was your weekend?\"}, \n",
    "    {\"output\": \"Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8f35514-aa7c-4b7d-a43d-c5fa74cfb07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hey, how are you? How was your weekend?\n",
      "AI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\n",
      "Human: Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\n",
      "AI: In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"}, \n",
    "    {\"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27591adf-5845-458f-944e-fe9596d7bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72bb19e5-0b00-44d0-bc5b-839e91e4a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hey, how are you? How was your weekend?\n",
      "AI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hey, how are you? How was your weekend?\"}, \n",
    "    {\"output\": \"Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0100b5e8-0883-41d4-9d4f-e25775936153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\n",
      "AI: In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"}, \n",
    "    {\"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d27cce43-43af-4923-bf25-ba4fce899727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(\n",
    "    llm = ChatOpenAI(temperature=0.1, model = 'gpt-4-1106-preview'), \n",
    "    max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19f13d79-99b3-4b88-a82b-85ea89a453c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hey, how are you? How was your weekend?\n",
      "AI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hey, how are you? How was your weekend?\"}, \n",
    "    {\"output\": \"Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "333232a8-59f0-4d30-9b7b-b2bd2cccd96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"}, \n",
    "    {\"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "154a5d72-71cd-4ba7-965e-a7e1cbb478b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00111d3b-59a3-4481-b581-f6555657f3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm = ChatOpenAI(temperature=0.1, model = 'gpt-4-1106-preview'), \n",
    "    max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c10f7ac-3b5c-48c6-a6ad-becc18fb33b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hey, how are you? How was your weekend?'), AIMessage(content='Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.')]\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hey, how are you? How was your weekend?\"}, \n",
    "    {\"output\": \"Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d46222c-b902-4b9c-b0c8-26841ab1fdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hey, how are you? How was your weekend?\n",
      "AI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5057dd2d-2862-480c-9f9a-36c58e798965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"summary\": \"\",\n",
      "  \"new_lines\": \"Human: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:LLMChain > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n\\n\\nNew lines of conversation:\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\n\\nNew summary:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:LLMChain > 2:llm:ChatOpenAI] [2.51s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The AI had a good weekend learning about LLM agents and describes it as magical. The human requests assistance with an urgent task from the CEO, asking for the absolute numbers and percentage difference of customers in London and Berlin in December 2023.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The AI had a good weekend learning about LLM agents and describes it as magical. The human requests assistance with an urgent task from the CEO, asking for the absolute numbers and percentage difference of customers in London and Berlin in December 2023.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 49,\n",
      "      \"prompt_tokens\": 213,\n",
      "      \"total_tokens\": 262\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LLMChain] [2.52s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The AI had a good weekend learning about LLM agents and describes it as magical. The human requests assistance with an urgent task from the CEO, asking for the absolute numbers and percentage difference of customers in London and Berlin in December 2023.\"\n",
      "}\n",
      "[AIMessage(content='In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.')]\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"}, \n",
    "    {\"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb45fa4c-c475-4cf1-8582-e6c2f4c2cc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The AI had a good weekend learning about LLM agents and describes it as magical. The human requests assistance with an urgent task from the CEO, asking for the absolute numbers and percentage difference of customers in London and Berlin in December 2023.\n",
      "AI: In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d53cd3c2-fac2-40a5-935f-98057cd0cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Hey, how are you? How was your weekend?\n",
      "AI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\n",
      "Human: Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(\"Human: Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n\\n\\nNew lines of conversation:\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonder time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\n\\nNew summary:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b697f-c544-4d1b-aab4-dd56e7826137",
   "metadata": {},
   "source": [
    "###Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83b1a363-3950-4a40-ba03-e17872e74fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa1fa5bd-4cea-4a42-8bb0-d3e67d639b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "system_message = '''\n",
    "You are working as a product analyst for the e-commerce company. \n",
    "Your work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \n",
    "If you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\n",
    "You are very helpful and try your best to answer the questions.\n",
    "\n",
    "If you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \n",
    "You don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \n",
    "Always use tool if you have follow-up questions to the request.\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "tools = [get_monthly_active_users, percentage_difference, human_tool]\n",
    "\n",
    "human_input_agent = create_openai_tools_agent(\n",
    "    llm = ChatOpenAI(temperature=0.1, model = 'gpt-4-1106-preview'),\n",
    "    tools = tools, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "human_input_agent_executor = AgentExecutor(\n",
    "    agent=human_input_agent, tools=tools, \n",
    "    verbose=True, max_iterations=10, # early stopping criteria\n",
    "    early_stopping_method='generate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9017cf8c-37e3-498c-9932-5d25a22eb826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m4286\u001b[0m\u001b[32;1m\u001b[1;3mThe number of active customers in London in December 2023 was 4,286.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the number of customers in London in December 2023?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'The number of active customers in London in December 2023 was 4,286.'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input_agent_executor.invoke(\n",
    "    {'input': 'What are the number of customers in London in December 2023?', \n",
    "     'agent_scratchpad': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b41f5100-ec4b-4e8e-8cfe-ffc88cf9e234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `human` with `Could you please specify the details of the data you are looking for regarding Berlin? Are you interested in monthly active users, sales figures, or another specific metric?`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "Could you please specify the details of the data you are looking for regarding Berlin? Are you interested in monthly active users, sales figures, or another specific metric?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " monthly active users in December 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mmonthly active users in December 2023\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2143\u001b[0m\u001b[32;1m\u001b[1;3mThe number of monthly active users in Berlin for December 2023 was 2,143.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'And what about Berlin?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'The number of monthly active users in Berlin for December 2023 was 2,143.'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input_agent_executor.invoke(\n",
    "    {'input': 'And what about Berlin?', \n",
    "     'agent_scratchpad': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "38b5cddb-ea4c-4c2a-90da-2b74f94160d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hey, how are you? How was your weekend?'), AIMessage(content='Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.')]\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, memory_key=\"chat_history\")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hey, how are you? How was your weekend?\"}, \n",
    "    {\"output\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"}\n",
    ")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d2cb7412-5de9-4194-b1de-ae2829455af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0f802dbb-8a8a-41da-8111-f6b1c235ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_monthly_active_users(month: str, city: str = None) -> int - Returns number of active customers for the specified month. Pass month in format %Y-%m-01.'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_monthly_active_users.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c1cc85ea-e17a-46a0-82d6-458c82b710f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marie/Documents/github/llm_env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "tools = [get_monthly_active_users, percentage_difference, human_tool]\n",
    "\n",
    "human_input_agent = create_openai_tools_agent(\n",
    "    llm = ChatOpenAI(temperature=0.1, model = 'gpt-4-1106-preview'),\n",
    "    tools = tools, \n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "human_input_agent_executor = AgentExecutor(\n",
    "    agent=human_input_agent, tools=tools, \n",
    "    verbose=True, max_iterations=10, # early stopping criteria\n",
    "    early_stopping_method = 'generate', memory = memory,\n",
    "    handle_parsing_errors = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "aead9e63-8508-444b-9804-c2528794e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:<lambda>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is the number of customers in London?\",\n",
      "  \"chat_history\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"HumanMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What is the number of customers in London?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: What is the number of customers in London?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] [2.10s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                    \"name\": \"human\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 36,\n",
      "      \"prompt_tokens\": 492,\n",
      "      \"total_tokens\": 528\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_6aca3b5ce1\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"OpenAIToolAgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"human\",\n",
      "        \"tool_input\": \"Could you please specify the time period for which you would like to know the number of customers in London?\",\n",
      "        \"log\": \"\\nInvoking: `human` with `Could you please specify the time period for which you would like to know the number of customers in London?`\\n\\n\\n\",\n",
      "        \"message_log\": [\n",
      "          {\n",
      "            \"lc\": 1,\n",
      "            \"type\": \"constructor\",\n",
      "            \"id\": [\n",
      "              \"langchain\",\n",
      "              \"schema\",\n",
      "              \"messages\",\n",
      "              \"AIMessage\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"content\": \"\",\n",
      "              \"additional_kwargs\": {\n",
      "                \"tool_calls\": [\n",
      "                  {\n",
      "                    \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "                    \"function\": {\n",
      "                      \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                      \"name\": \"human\"\n",
      "                    },\n",
      "                    \"type\": \"function\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [2.11s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:human] Entering Tool run with input:\n",
      "\u001b[0m\"Could you please specify the time period for which you would like to know the number of customers in London?\"\n",
      "\n",
      "\n",
      "Could you please specify the time period for which you would like to know the number of customers in London?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " December 2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:human] [4.26s] Exiting Tool run with output:\n",
      "\u001b[0m\"December 2023\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad> > 13:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad> > 13:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                \"name\": \"human\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "        \"content\": \"December 2023\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"human\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is the number of customers in London?\",\n",
      "  \"chat_history\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"HumanMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"human\",\n",
      "          \"tool_input\": \"Could you please specify the time period for which you would like to know the number of customers in London?\",\n",
      "          \"log\": \"\\nInvoking: `human` with `Could you please specify the time period for which you would like to know the number of customers in London?`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                        \"name\": \"human\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\"\n",
      "        }\n",
      "      },\n",
      "      \"December 2023\"\n",
      "    ]\n",
      "  ],\n",
      "  \"agent_scratchpad\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                \"name\": \"human\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "        \"content\": \"December 2023\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"human\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 14:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 14:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What is the number of customers in London?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                  \"name\": \"human\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "          \"content\": \"December 2023\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"human\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 15:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: What is the number of customers in London?\\nAI: \\nTool: December 2023\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 15:llm:ChatOpenAI] [2.69s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 26,\n",
      "      \"prompt_tokens\": 539,\n",
      "      \"total_tokens\": 565\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 16:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 16:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"OpenAIToolAgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"get_monthly_active_users\",\n",
      "        \"tool_input\": {\n",
      "          \"month\": \"2023-12-01\",\n",
      "          \"city\": \"London\"\n",
      "        },\n",
      "        \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "        \"message_log\": [\n",
      "          {\n",
      "            \"lc\": 1,\n",
      "            \"type\": \"constructor\",\n",
      "            \"id\": [\n",
      "              \"langchain\",\n",
      "              \"schema\",\n",
      "              \"messages\",\n",
      "              \"AIMessage\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"content\": \"\",\n",
      "              \"additional_kwargs\": {\n",
      "                \"tool_calls\": [\n",
      "                  {\n",
      "                    \"id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "                    \"function\": {\n",
      "                      \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                      \"name\": \"get_monthly_active_users\"\n",
      "                    },\n",
      "                    \"type\": \"function\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"tool_call_id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence] [2.70s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 17:tool:get_monthly_active_users] Entering Tool run with input:\n",
      "\u001b[0m\"{'month': '2023-12-01', 'city': 'London'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 17:tool:get_monthly_active_users] [0ms] Exiting Tool run with output:\n",
      "\u001b[0m\"4286\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad> > 20:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad> > 20:chain:RunnableParallel<agent_scratchpad> > 21:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad> > 20:chain:RunnableParallel<agent_scratchpad> > 21:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                \"name\": \"human\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "        \"content\": \"December 2023\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"human\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "        \"content\": \"4286\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad> > 20:chain:RunnableParallel<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 19:chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is the number of customers in London?\",\n",
      "  \"chat_history\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"HumanMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"human\",\n",
      "          \"tool_input\": \"Could you please specify the time period for which you would like to know the number of customers in London?\",\n",
      "          \"log\": \"\\nInvoking: `human` with `Could you please specify the time period for which you would like to know the number of customers in London?`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                        \"name\": \"human\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\"\n",
      "        }\n",
      "      },\n",
      "      \"December 2023\"\n",
      "    ],\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"London\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'London'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\"\n",
      "        }\n",
      "      },\n",
      "      4286\n",
      "    ]\n",
      "  ],\n",
      "  \"agent_scratchpad\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                \"name\": \"human\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "        \"content\": \"December 2023\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"human\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "        \"content\": \"4286\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 22:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 22:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What is the number of customers in London?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"__arg1\\\":\\\"Could you please specify the time period for which you would like to know the number of customers in London?\\\"}\",\n",
      "                  \"name\": \"human\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_CsdSDFhzaRBzFzcm9yJWKoCU\",\n",
      "          \"content\": \"December 2023\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"human\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"London\\\"}\",\n",
      "                  \"name\": \"get_monthly_active_users\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_gPzLtC9FZoZJioKJL0NETnE5\",\n",
      "          \"content\": \"4286\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 23:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: What is the number of customers in London?\\nAI: \\nTool: December 2023\\nAI: \\nTool: 4286\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 23:llm:ChatOpenAI] [1.31s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The number of active customers in London for December 2023 is 4,286.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The number of active customers in London for December 2023 is 4,286.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 19,\n",
      "      \"prompt_tokens\": 578,\n",
      "      \"total_tokens\": 597\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 24:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence > 24:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"schema\",\n",
      "    \"agent\",\n",
      "    \"AgentFinish\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"return_values\": {\n",
      "      \"output\": \"The number of active customers in London for December 2023 is 4,286.\"\n",
      "    },\n",
      "    \"log\": \"The number of active customers in London for December 2023 is 4,286.\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 18:chain:RunnableSequence] [1.32s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [10.41s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The number of active customers in London for December 2023 is 4,286.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the number of customers in London?',\n",
       " 'chat_history': [HumanMessage(content='Hey, how are you? How was your weekend?'),\n",
       "  AIMessage(content='Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.'),\n",
       "  HumanMessage(content='What is the number of customers in London?'),\n",
       "  AIMessage(content='The number of active customers in London for December 2023 is 4,286.')],\n",
       " 'output': 'The number of active customers in London for December 2023 is 4,286.'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input_agent_executor.invoke(\n",
    "    {'input': 'What is the number of customers in London?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6289b10a-f7d3-46fa-b9ec-701cb2b3f3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      "You are working as a product analyst for the e-commerce company. \n",
      "Your work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \n",
      "If you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\n",
      "You are very helpful and try your best to answer the questions.\n",
      "\n",
      "If you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \n",
      "You don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \n",
      "Always use tool if you have follow-up questions to the request.\n",
      "\n",
      "Human: Hey, how are you? How was your weekend?\n",
      "AI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\n",
      "Human: What is the number of customers in London?\n"
     ]
    }
   ],
   "source": [
    "print(\"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: What is the number of customers in London?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c51b32c0-874a-4842-81b5-947ba300e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:<lambda>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is the number for Berlin?\",\n",
      "  \"chat_history\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"HumanMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"HumanMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"What is the number of customers in London?\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"The number of active customers in London for December 2023 is 4,286.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What is the number of customers in London?\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The number of active customers in London for December 2023 is 4,286.\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What is the number for Berlin?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: What is the number of customers in London?\\nAI: The number of active customers in London for December 2023 is 4,286.\\nHuman: What is the number for Berlin?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] [1.61s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                    \"name\": \"get_monthly_active_users\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 26,\n",
      "      \"prompt_tokens\": 525,\n",
      "      \"total_tokens\": 551\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"OpenAIToolAgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"get_monthly_active_users\",\n",
      "        \"tool_input\": {\n",
      "          \"month\": \"2023-12-01\",\n",
      "          \"city\": \"Berlin\"\n",
      "        },\n",
      "        \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\\n\\n\\n\",\n",
      "        \"message_log\": [\n",
      "          {\n",
      "            \"lc\": 1,\n",
      "            \"type\": \"constructor\",\n",
      "            \"id\": [\n",
      "              \"langchain\",\n",
      "              \"schema\",\n",
      "              \"messages\",\n",
      "              \"AIMessage\"\n",
      "            ],\n",
      "            \"kwargs\": {\n",
      "              \"content\": \"\",\n",
      "              \"additional_kwargs\": {\n",
      "                \"tool_calls\": [\n",
      "                  {\n",
      "                    \"id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "                    \"function\": {\n",
      "                      \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                      \"name\": \"get_monthly_active_users\"\n",
      "                    },\n",
      "                    \"type\": \"function\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"tool_call_id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [1.62s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_monthly_active_users] Entering Tool run with input:\n",
      "\u001b[0m\"{'month': '2023-12-01', 'city': 'Berlin'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:get_monthly_active_users] [1ms] Exiting Tool run with output:\n",
      "\u001b[0m\"2143\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad> > 13:chain:<lambda>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad> > 13:chain:<lambda>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "        \"content\": \"2143\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad> > 12:chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 11:chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is the number for Berlin?\",\n",
      "  \"chat_history\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"HumanMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"HumanMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"What is the number of customers in London?\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"The number of active customers in London for December 2023 is 4,286.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"intermediate_steps\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"agent\",\n",
      "          \"OpenAIToolAgentAction\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool\": \"get_monthly_active_users\",\n",
      "          \"tool_input\": {\n",
      "            \"month\": \"2023-12-01\",\n",
      "            \"city\": \"Berlin\"\n",
      "          },\n",
      "          \"log\": \"\\nInvoking: `get_monthly_active_users` with `{'month': '2023-12-01', 'city': 'Berlin'}`\\n\\n\\n\",\n",
      "          \"message_log\": [\n",
      "            {\n",
      "              \"lc\": 1,\n",
      "              \"type\": \"constructor\",\n",
      "              \"id\": [\n",
      "                \"langchain\",\n",
      "                \"schema\",\n",
      "                \"messages\",\n",
      "                \"AIMessage\"\n",
      "              ],\n",
      "              \"kwargs\": {\n",
      "                \"content\": \"\",\n",
      "                \"additional_kwargs\": {\n",
      "                  \"tool_calls\": [\n",
      "                    {\n",
      "                      \"id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "                      \"function\": {\n",
      "                        \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                        \"name\": \"get_monthly_active_users\"\n",
      "                      },\n",
      "                      \"type\": \"function\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"tool_call_id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\"\n",
      "        }\n",
      "      },\n",
      "      2143\n",
      "    ]\n",
      "  ],\n",
      "  \"agent_scratchpad\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "              \"function\": {\n",
      "                \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                \"name\": \"get_monthly_active_users\"\n",
      "              },\n",
      "              \"type\": \"function\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"ToolMessage\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool_call_id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "        \"content\": \"2143\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"name\": \"get_monthly_active_users\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 14:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 14:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Hey, how are you? How was your weekend?\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What is the number of customers in London?\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The number of active customers in London for December 2023 is 4,286.\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What is the number for Berlin?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"AIMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "                \"function\": {\n",
      "                  \"arguments\": \"{\\\"month\\\":\\\"2023-12-01\\\",\\\"city\\\":\\\"Berlin\\\"}\",\n",
      "                  \"name\": \"get_monthly_active_users\"\n",
      "                },\n",
      "                \"type\": \"function\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"ToolMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"tool_call_id\": \"call_YHg2RAYFxmBvxuFkmvdlD31o\",\n",
      "          \"content\": \"2143\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"name\": \"get_monthly_active_users\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 15:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: What is the number of customers in London?\\nAI: The number of active customers in London for December 2023 is 4,286.\\nHuman: What is the number for Berlin?\\nAI: \\nTool: 2143\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 15:llm:ChatOpenAI] [1.57s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The number of active customers in Berlin for December 2023 is 2,143.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The number of active customers in Berlin for December 2023 is 2,143.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 19,\n",
      "      \"prompt_tokens\": 564,\n",
      "      \"total_tokens\": 583\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-1106-preview\",\n",
      "    \"system_fingerprint\": \"fp_168383a679\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 16:parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence > 16:parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"schema\",\n",
      "    \"agent\",\n",
      "    \"AgentFinish\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"return_values\": {\n",
      "      \"output\": \"The number of active customers in Berlin for December 2023 is 2,143.\"\n",
      "    },\n",
      "    \"log\": \"The number of active customers in Berlin for December 2023 is 2,143.\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:RunnableSequence] [1.58s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [3.21s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The number of active customers in Berlin for December 2023 is 2,143.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the number for Berlin?',\n",
       " 'chat_history': [HumanMessage(content='Hey, how are you? How was your weekend?'),\n",
       "  AIMessage(content='Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.'),\n",
       "  HumanMessage(content='What is the number of customers in London?'),\n",
       "  AIMessage(content='The number of active customers in London for December 2023 is 4,286.'),\n",
       "  HumanMessage(content='What is the number for Berlin?'),\n",
       "  AIMessage(content='The number of active customers in Berlin for December 2023 is 2,143.')],\n",
       " 'output': 'The number of active customers in Berlin for December 2023 is 2,143.'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input_agent_executor.invoke(\n",
    "    {'input': 'What is the number for Berlin?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0d591e6a-2623-401e-a482-8cee4944f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: \n",
      "You are working as a product analyst for the e-commerce company. \n",
      "Your work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \n",
      "If you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\n",
      "You are very helpful and try your best to answer the questions.\n",
      "\n",
      "If you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \n",
      "You don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \n",
      "Always use tool if you have follow-up questions to the request.\n",
      "\n",
      "Human: Hey, how are you? How was your weekend?\n",
      "AI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\n",
      "Human: What is the number of customers in London?\n",
      "AI: The number of active customers in London for December 2023 is 4,286.\n",
      "Human: What is the number for Berlin?\n"
     ]
    }
   ],
   "source": [
    "print(\"System: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you're not sure about the details of the request, you don't provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don't have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don't make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\nHuman: What is the number of customers in London?\\nAI: The number of active customers in London for December 2023 is 4,286.\\nHuman: What is the number for Berlin?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd972d8-fda2-4530-91c3-c23d1089d93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
